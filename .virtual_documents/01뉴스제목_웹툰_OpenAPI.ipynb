


!pip show requests


!pip show beautifulsoup4


import requests
import bs4
from bs4 import BeautifulSoup


print(f'request ver {requests.__version__}' )
print('beautifulsoup {}'.format(bs4.__version__))





# IT/과학 뉴스
req_param = {
    's_id': 105
}
url = 'https://news.naver.com/section/{s_id}'.format(**req_param)
# 요청 헤더 설정 : 브라우저 정보
req_header = {
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36'
}

res = requests.get(url, headers=req_header)
if res.ok:
    soup = BeautifulSoup(res.text, "html.parser")
    #print(len(soup.select("a[href*='https://n.news.naver.com/mnews/article/']")))
    print(len(soup.select("div.sa_text a[href*='https://n.news.naver.com/mnews/article/']")))
    atag_list = soup.select("div.sa_text a.sa_text_title")
    for atag in atag_list:
        print(type(atag))
        title = atag.text.strip()
        url = atag['href']
        print(f'{title}: {url}')
        print('-----------')
else:
    print(f'Error: {res.status_code}')



section_dict = {100:'정치',101:'경제',102:'사회',103:'생활/문화',104:'세계',105:'IT/과학'}





import requests
from bs4 import BeautifulSoup

def print_news(sid, section):    
    # 요청 Parameter
    req_param = {
    'sid': sid
    }
    url = 'https://news.naver.com/section/{sid}'.format(**req_param)
    
    print(f'======> {url} {section} 뉴스 <======')
    
    # 요청 헤더 설정 : 브라우저 정보
    req_header = {
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36'
    }
    res = requests.get(url, headers=req_header)
    if res.ok:
        soup = BeautifulSoup(res.text, "html.parser")
        atag_list = soup.select("div.sa_text a.sa_text_title")
        for atag in atag_list:
            title = atag.text.strip()
            url = atag['href']
            print(f'{title}: {url}')
            print('-----------')
    else:
        print(f'Error: {res.status_code}')
    


print_news(103,section_dict[103])








import requests
import os

req_header = {
    'referer':'https://comic.naver.com/webtoon/detail?titleId=798173&no=5&amp;weekday=thu'
}
img_urls = [
    'https://image-comic.pstatic.net/webtoon/798173/5/20220804112251_d97bd1e1b38f0cd022e4e3639d2926b3_IMAG01_1.jpg',
    'https://image-comic.pstatic.net/webtoon/798173/5/20220804112251_d97bd1e1b38f0cd022e4e3639d2926b3_IMAG01_2.jpg',
    'https://image-comic.pstatic.net/webtoon/798173/5/20220804112251_d97bd1e1b38f0cd022e4e3639d2926b3_IMAG01_3.jpg'
]
for img_url in img_urls:
    res = requests.get(img_url, headers=req_header)
    if res.ok:
        img_data = res.content
        file_name = os.path.basename(img_url)
        with open(file_name, 'wb') as file:
            print(f'writing to {file_name} ({len(img_data)})')
            file.write(img_data)






import requests
import os

webtoon_url = 'https://comic.naver.com/webtoon/detail?titleId=817945&no=37&week=mon'
req_header = {
    'referer': webtoon_url
}
res = requests.get(webtoon_url, req_header)
if res.ok: #200
    soup = BeautifulSoup(res.text, 'html.parser')
    img_tag_list = soup.select("img[src*='IMAG01']")
    img_url_list = [img_tag['src'] for img_tag in img_tag_list]
    image_dir_name = 'img'
    if not os.path.isdir(image_dir_name):
        os.mkdir(image_dir_name)
    for idx, img_url in enumerate(img_url_list):
        res = requests.get(img_url, headers=req_header)
        if res.ok:
            img_data = res.content
            file_name = os.path.basename(img_url)
            with open(os.path.join(image_dir_name, file_name), 'wb') as file:
                print(f'writing to {os.path.join(image_dir_name, file_name)} ({len(img_data)})')
                file.write(img_data)
else:
    print(res.status_code)





import requests

upload_dict = {
    "img1": open("img/soup.png", "rb"),
    "img2": open("img/java.png", "rb")
}
url = "http://httpbin.org/post"
res = requests.post(url, files=upload_dict)
print(res.status_code)
print(res.json()['files']['img1'])





import os
import sys
import urllib.request

client_id = "HqlSFjKmloQ6puyvhW49" # 개발자센터에서 발급받은 Client ID 값
client_secret = "qfI33WIrRD" # 개발자센터에서 발급받은 Client Secret 값
encText = urllib.parse.quote("https://drive.google.com/drive/u/0/folders/1V_DK7Px5w_niEKLlWhDr_GPgIYHG3Du-")
data = "url=" + encText
url = "https://openapi.naver.com/v1/util/shorturl"

request = urllib.request.Request(url)
request.add_header("X-Naver-Client-Id",client_id)
request.add_header("X-Naver-Client-Secret",client_secret)

response = urllib.request.urlopen(request, data=data.encode("utf-8"))
rescode = response.getcode()
if(rescode==200):
    response_body = response.read()
    print(response_body.decode('utf-8'))
else:
    print("Error Code:" + rescode)






import requests

client_id = "HqlSFjKmloQ6puyvhW49" # 개발자센터에서 발급받은 Client ID 값
client_secret = "qfI33WIrRD" # 개발자센터에서 발급받은 Client Secret 값

origin_url = "https://drive.google.com/drive/u/0/folders/1V_DK7Px5w_niEKLlWhDr_GPgIYHG3Du-"

req_param = {
    "url": origin_url
}
req_header= {
    "X-Naver-Client-Id": client_id,
    "X-Naver-Client-Secret": client_secret
}
service_url = "https://openapi.naver.com/v1/util/shorturl"
res = requests.post(service_url, req_param, headers=req_header)
if res.status_code:
    print(res.json())





import requests
import pprint

headers = {
    'X-Naver-Client-Id': 'V',
    'X-Naver-Client-Secret': 'y_',
}

payload = {
    'query': '파이썬',
    'display': 100,
    'sort': 'sim'
}

url = 'https://openapi.naver.com/v1/search/blog.json'

res = requests.get(url, params=payload, headers=headers)
items_data = res.json()['items']
#print(items_data)

items_list = list()
item_list = []
for item in items_data:
#     print(item)
    item_list.append(item['title'])
    item_list.append(item['bloggername'])
    item_list.append(item['description'])
    item_list.append(item['bloggerlink'])
    item_list.append(item['link'])

    items_list.append(item_list)
    item_list = []

print(items_list)

with open('data/nhnblog.txt','w',encoding="utf-8")as file:
    for items in items_list:
        for item in items:
            item = item + '\n'
            file.write(item)
        file.write('-'*150+'\n')
