


!pip show requests


!pip show beautifulsoup4


import requests
import bs4
from bs4 import BeautifulSoup


print(f'request ver {requests.__version__}' )
print('beautifulsoup {}'.format(bs4.__version__))





# IT/과학 뉴스

# 요청 헤더 설정 : 브라우저 정보
req_header = {
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36'
}



section_dict = {100:'정치',101:'경제',102:'사회',103:'생활/문화',104:'세계',105:'IT/과학'}





import requests
from bs4 import BeautifulSoup

def print_news(sid, section):    
    # 요청 Parameter
    req_param = {
    'sid': sid
    }
    url = 'https://news.naver.com/section/{sid}'.format(**req_param)
    
    print(f'======> {url} {section} 뉴스 <======')
    
    # 요청 헤더 설정 : 브라우저 정보
    req_header = {
        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36'
    }
    


print_news(103,section_dict[103])





import requests
import os

req_header = {
    'referer':'https://comic.naver.com/webtoon/detail?titleId=798173&no=5&amp;weekday=thu'
}
img_urls = [
    'https://image-comic.pstatic.net/webtoon/798173/5/20220804112251_d97bd1e1b38f0cd022e4e3639d2926b3_IMAG01_1.jpg',
    'https://image-comic.pstatic.net/webtoon/798173/5/20220804112251_d97bd1e1b38f0cd022e4e3639d2926b3_IMAG01_2.jpg',
    'https://image-comic.pstatic.net/webtoon/798173/5/20220804112251_d97bd1e1b38f0cd022e4e3639d2926b3_IMAG01_3.jpg'
]







import requests
import os

url = 'https://comic.naver.com/webtoon/detail?titleId=817945&no=37&week=mon'
req_header = {
    'referer': url
}
res = requests.get(url)
if res.ok: #200
    pass
else:
    print(res.status_code)











import os
import sys
import urllib.request

client_id = "V" # 개발자센터에서 발급받은 Client ID 값
client_secret = "y_" # 개발자센터에서 발급받은 Client Secret 값
encText = urllib.parse.quote("https://drive.google.com/drive/u/0/folders/1V_DK7Px5w_niEKLlWhDr_GPgIYHG3Du-")
data = "url=" + encText
url = "https://openapi.naver.com/v1/util/shorturl"

request = urllib.request.Request(url)
request.add_header("X-Naver-Client-Id",client_id)
request.add_header("X-Naver-Client-Secret",client_secret)

response = urllib.request.urlopen(request, data=data.encode("utf-8"))
rescode = response.getcode()
if(rescode==200):
    response_body = response.read()
    print(response_body.decode('utf-8'))
else:
    print("Error Code:" + rescode)






import requests

client_id = "V" # 개발자센터에서 발급받은 Client ID 값
client_secret = "y_" # 개발자센터에서 발급받은 Client Secret 값

origin_url = "https://drive.google.com/drive/u/0/folders/1V_DK7Px5w_niEKLlWhDr_GPgIYHG3Du-"







import requests
import pprint

headers = {
    'X-Naver-Client-Id': 'V',
    'X-Naver-Client-Secret': 'y_',
}

payload = {
    'query': '파이썬',
    'display': 100,
    'sort': 'sim'
}

url = 'https://openapi.naver.com/v1/search/blog.json'

res = requests.get(url, params=payload, headers=headers)
items_data = res.json()['items']
#print(items_data)

items_list = list()
item_list = []
for item in items_data:
#     print(item)
    item_list.append(item['title'])
    item_list.append(item['bloggername'])
    item_list.append(item['description'])
    item_list.append(item['bloggerlink'])
    item_list.append(item['link'])

    items_list.append(item_list)
    item_list = []

print(items_list)

with open('data/nhnblog.txt','w',encoding="utf-8")as file:
    for items in items_list:
        for item in items:
            item = item + '\n'
            file.write(item)
        file.write('-'*150+'\n')
